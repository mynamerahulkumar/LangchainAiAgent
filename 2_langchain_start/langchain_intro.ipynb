{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking and tracing\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x14b215970> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x14b216a50> root_client=<openai.OpenAI object at 0x14afe00b0> root_async_client=<openai.AsyncOpenAI object at 0x14b023920> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"o1-mini\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"**LangChain AI** is an open-source framework designed to simplify the development of applications that leverage large language models (LLMs) like OpenAI's GPT series. By providing a suite of modular components, LangChain enables developers to build sophisticated, AI-driven applications with ease, facilitating tasks such as natural language understanding, generation, and interaction.\\n\\n### Key Features of LangChain AI:\\n\\n1. **Modular Design:**\\n   - **Chains:** These are sequences of actions or operations that process inputs and produce outputs. Chains can be simple (e.g., a single step) or complex (involving multiple steps and decision points).\\n   - **Agents:** Agents can make decisions about which actions to take based on user inputs and external data sources. They allow for more dynamic and interactive applications.\\n   - **Memory:** LangChain supports memory management, enabling applications to remember past interactions, which is crucial for creating coherent and context-aware conversations.\\n\\n2. **Integration with Data Sources:**\\n   - LangChain provides connectors to various data sources such as databases, APIs, and document stores. This allows LLMs to access and incorporate real-time or specialized data into their responses.\\n   \\n3. **Support for Multiple LLM Providers:**\\n   - While initially built with OpenAI's models in mind, LangChain is designed to be provider-agnostic, supporting multiple LLM services. This flexibility allows developers to choose the best model for their specific needs or switch providers as needed.\\n\\n4. **Utilities and Tools:**\\n   - **Prompt Management:** Tools for crafting, testing, and optimizing prompts to get the best performance from LLMs.\\n   - **Evaluation Tools:** Mechanisms to assess the performance and accuracy of generated responses.\\n   - **Debugging Tools:** Features that help identify and fix issues within the application flow or model outputs.\\n\\n### Common Use Cases:\\n\\n- **Chatbots and Virtual Assistants:** Creating conversational agents that can handle complex dialogues, understand context, and provide accurate responses.\\n- **Content Generation:** Automating the creation of content such as articles, summaries, and reports.\\n- **Question-Answering Systems:** Building systems that can retrieve and synthesize information from various sources to answer user queries effectively.\\n- **Data Analysis and Interpretation:** Assisting in analyzing datasets by generating insights, explanations, and visualizations based on the data.\\n\\n### Advantages of Using LangChain AI:\\n\\n- **Efficiency:** Accelerates the development process by providing ready-to-use components and integrations.\\n- **Scalability:** Allows applications to grow in complexity without significant rewrites, thanks to its modular architecture.\\n- **Flexibility:** Supports a wide range of applications and can be tailored to specific use cases or industry requirements.\\n- **Community and Support:** Being open-source, LangChain benefits from a growing community contributing plugins, enhancements, and support resources.\\n\\n### Getting Started:\\n\\nTo begin using LangChain AI, you can install it via pip:\\n\\n```bash\\npip install langchain\\n```\\n\\nAfter installation, you can explore various modules and examples provided in the [official documentation](https://langchain.com/docs/) to build your desired application.\\n\\n### Conclusion\\n\\nLangChain AI bridges the gap between powerful language models and practical application development. Its comprehensive set of tools and integrations make it easier for developers to harness the capabilities of LLMs, enabling the creation of intelligent, responsive, and context-aware applications across various domains.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 886, 'prompt_tokens': 13, 'total_tokens': 899, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_5c373483f1', 'finish_reason': 'stop', 'logprobs': None} id='run-4df5ea16-6d92-4214-bf59-2ea0500058b8-0' usage_metadata={'input_tokens': 13, 'output_tokens': 886, 'total_tokens': 899, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"What is Langchain AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI engineer.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI engineer.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='As of my last update in October 2023, \"LangGraph\" is not a widely known or recognized term, and it does not appear to have a specific definition or framework associated with it in the public domain. It\\'s possible that it could be a new technology, a product, a research paper, or even a startup that has emerged very recently or has niche application.\\n\\nIf \"LangGraph\" refers to a specific technology or framework, its name suggests that it might be related to language processing utilizing graph structures. Graph-based models have been used in various natural language processing (NLP) applications, particularly for semantic analysis, knowledge representation, and network-based understanding.\\n\\nFor updated information, I recommend checking recent publications, technology forums, or news sources. If you have more context on how \"LangGraph\" is used or its field of application, I might be able to provide more targeted insights or suggestions.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 182, 'prompt_tokens': 32, 'total_tokens': 214, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None} id='run-87f6754b-cc43-4ee5-a4eb-cfc315bb2abf-0' usage_metadata={'input_tokens': 32, 'output_tokens': 182, 'total_tokens': 214, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|llm \n",
    "response=chain.invoke({\"input\":\"Can you tell me about langgraph\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in October 2023, \"LangGraph\" is not a widely known or recognized term, and it does not appear to have a specific definition or framework associated with it in the public domain. It's possible that it could be a new technology, a product, a research paper, or even a startup that has emerged very recently or has niche application.\n",
      "\n",
      "If \"LangGraph\" refers to a specific technology or framework, its name suggests that it might be related to language processing utilizing graph structures. Graph-based models have been used in various natural language processing (NLP) applications, particularly for semantic analysis, knowledge representation, and network-based understanding.\n",
      "\n",
      "For updated information, I recommend checking recent publications, technology forums, or news sources. If you have more context on how \"LangGraph\" is used or its field of application, I might be able to provide more targeted insights or suggestions.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Json Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instrunctions': 'Return a JSON object.'}, template='Answer the user query.\\n{format_instrunctions}\\n{query}\\n')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instrunctions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instrunctions\":output_parser.get_format_instructions()},\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LangGraph': {'Definition': 'LangGraph is a language learning tool designed to improve vocabulary and comprehension through contextual relationships and visual mapping.', 'Features': ['Visual representation of language connections', 'Helps learners see associations between words and phrases', 'Aids in vocabulary building and retention', 'Includes interactive modules for active learning'], 'Benefits': ['Enhances memory retention by linking concepts', 'Improves understanding of language structure', 'Facilitates faster learning through engaging interfaces', 'Customizable learning paths for personalized experiences'], 'Use Cases': ['Ideal for students and language enthusiasts', 'Can be used in educational institutions for language courses', 'Suitable for self-study learners seeking interactive tools']}}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|llm|output_parser\n",
    "response=chain.invoke({\"query\":\"Can you tell me about langgraph?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Definition': 'LangGraph is a language learning tool designed to improve vocabulary and comprehension through contextual relationships and visual mapping.', 'Features': ['Visual representation of language connections', 'Helps learners see associations between words and phrases', 'Aids in vocabulary building and retention', 'Includes interactive modules for active learning'], 'Benefits': ['Enhances memory retention by linking concepts', 'Improves understanding of language structure', 'Facilitates faster learning through engaging interfaces', 'Customizable learning paths for personalized experiences'], 'Use Cases': ['Ideal for students and language enthusiasts', 'Can be used in educational institutions for language courses', 'Suitable for self-study learners seeking interactive tools']}\n"
     ]
    }
   ],
   "source": [
    "print(response[\"LangGraph\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

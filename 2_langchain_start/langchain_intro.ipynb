{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking and tracing\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x11fd62c30> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11fd92900> root_client=<openai.OpenAI object at 0x11e680aa0> root_async_client=<openai.AsyncOpenAI object at 0x11e680590> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"o1-mini\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"LangChain is an open-source framework designed to simplify the development of applications that leverage large language models (LLMs) like OpenAI's GPT series. It provides a set of tools and abstractions that enable developers to build more sophisticated and capable AI-driven applications by seamlessly integrating language models with other components, data sources, and services.\\n\\n### **Key Features of LangChain:**\\n\\n1. **Modular Architecture:**\\n   - **Chains:** These are sequences of actions or calls that allow you to define workflows involving language models and other utilities. Chains can be customized to perform tasks like data retrieval, processing, and response generation.\\n   - **Agents:** These components can make decisions about which actions to take based on user input or other triggers. They can interact with external tools, databases, or APIs to perform complex operations.\\n   - **Memory:** LangChain supports persistent memory, allowing applications to maintain context across interactions. This is crucial for creating conversational agents that remember past interactions.\\n\\n2. **Integrations:**\\n   - **Data Sources:** LangChain can connect to various data sources such as databases, APIs, and file systems, enabling language models to access and manipulate external information.\\n   - **Tools and Services:** It integrates with tools like search engines, calculators, and other utilities, allowing language models to extend their capabilities beyond text generation.\\n\\n3. **Utilities:**\\n   - **Prompt Management:** LangChain offers utilities for managing and optimizing prompts, helping developers craft effective inputs for language models.\\n   - **Evaluation:** Tools for assessing the performance and responses of language models to ensure quality and relevance.\\n\\n4. **Support for Multiple LLMs:**\\n   - While LangChain is often associated with OpenAI's models, it is designed to be agnostic, supporting various language models from different providers. This flexibility allows developers to choose the most suitable model for their specific needs.\\n\\n### **Use Cases:**\\n\\n- **Conversational Agents:** Building chatbots that can maintain context over multiple interactions, understand user intent, and provide relevant responses.\\n- **Content Generation:** Creating tools for generating articles, summaries, or other forms of written content with the assistance of language models.\\n- **Data Analysis:** Developing applications that can interpret and analyze data, generate reports, or extract insights using natural language understanding.\\n- **Automation:** Automating tasks that involve interpreting instructions, accessing databases, or interacting with other software tools.\\n\\n### **Why Use LangChain?**\\n\\nDeveloping applications that effectively utilize large language models can be complex, involving challenges like managing context, integrating with various data sources, and handling the nuances of human language. LangChain abstracts much of this complexity by providing a structured framework, enabling developers to focus on building functionality rather than managing the intricate details of language model interactions.\\n\\nBy offering a cohesive set of tools and best practices, LangChain accelerates the development process, promotes scalability, and facilitates the creation of more intelligent and responsive applications.\\n\\n### **Getting Started:**\\n\\nTo start using LangChain, you can visit their [official GitHub repository](https://github.com/langchain-ai/langchain) which provides comprehensive documentation, installation instructions, and example projects. The community around LangChain is active, offering support and sharing best practices to help developers build effective AI-driven solutions.\\n\\n---\\n\\n**In Summary:** LangChain is a powerful framework that bridges the gap between large language models and practical application development. By providing modular components, integrations, and utilities, it empowers developers to create intelligent applications with enhanced capabilities, leveraging the strengths of modern language AI technologies.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 911, 'prompt_tokens': 13, 'total_tokens': 924, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_5c373483f1', 'finish_reason': 'stop', 'logprobs': None} id='run-2b4e5565-93f6-40a9-bbdd-dfc14be5e8cb-0' usage_metadata={'input_tokens': 13, 'output_tokens': 911, 'total_tokens': 924, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"What is Langchain AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
